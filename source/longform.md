---
title: Long Form
---
bad regex (a+)+

Do ToC @ LangSec pt

More pics

standards compliant XML is (probably) Recursively enumerable
another reason XML is like violence: If you use a standards compliant parser, it can eat your lunch

*most parsers add bounds which reduces XML power to context sensitive


talk about how MuskOx makes it easier to have more definite error messages.


TL;DR

* avoid impossible problems, like validating turing complete inputs
* validate inputs before parsing
* JSON > XML; it's just ducky


* introduce lang sec
* input validation as formal lang recognition
  * but not in a painful way

in order to do that I need to explain what formal lang is
explain chomsky hierarchy


eg

sanitizing text for HTML
regex can't do it because nesting and escapes
that's why rails' sanitizer is a parser

Rails doesn't do it, and neither should you!
http://api.rubyonrails.org/classes/ActionView/Helpers/SanitizeHelper.html uses a simple HTML parser




Two years ago, I went to a hacker conference called ShmooCon. It was a great experience. InfoSec is at once totally weird and very familiar. It's all about solving hard and sometimes unusual problems. Going made me feel like all the infrastructure I use on a day to day basis is held together w/ a bit of duct tape bailing wire and bubble gum. Not a pleasant feeling.

My favorite talk though, was the [Science of Insecurity](www.youtube.com/watch?v=F7etmSeivU8â€Ž) by Meredith L. Patterson & Sergey Bratus. For me it was mind candy. The idea was that it turns out you can use all that crap you learnt in Theory of Computation to prove things about the security of computational systems.

This was mind blowing to me. I'd enjoyed my theory courses, and occasionally saw how they might be useful, but this. This meant that ToC is vital to everything that talks over networks more or less. I obsessed about it for a few months, and then my excitement petered out and it became one of the things I rant about every now and then.

A year later, I found myself thinking about it again, but this time I'd connected it to another problem. Rails 4 had come out and with it a new way of validating input--strong params. This reminded me strongly of langsec and I dug into it.

I found an ambiguity in the pattern language it uses, but I couldn't find any examples of cases where you might be able to exploit it unintentionally. The ambiguity gave me an idea though. What if there was a tool for specifying inputs that let you be more precise, and what if it was baked safely into the parser in a way that took into account langsec principles.

Thus MuskOx was born. The idea behind muskox was to do input validation on the population interface of the parser. Instead of letting a parser just take data from the internet and make Ruby objects willy nilly, only create Ruby objects that conform to a specified schema.

So I hacked something together with a copy pasted version of the native Ruby implementation of JSON parsing and a push down automata that implements schema validation.

Just because the base language you are parsing isn't turing complete, doesn't mean your input language isn't.


qqqq
-----------

If the problem is that our code is so complex in its input handling, why would generating parsers make things better?


fear leads to anger
anger leads to hate
hate leads to suffering

just so



Cliffs Notes of Theory of Computation
-------------------------------------

a lot of Theory of Computation hinges around a few key concepts.
While there are others, eg computability, for this we only really care about decidability.

decidability is an old problem. It goes back to the debate about whether you can prove any statement within a formal system or whether formal systems of a particular complexity will inevitably have unprovable statements.

It turns out via Turing that formal systems with certain properties will be undecidable; that is there will be statements in the system that cannot be either true or false.

For computing, decidability usually reduces to the halting problem. The halting problem asks the question, "Given a piece of input, will this machine halt?" For Turing Machines, if you don't know the turing machines' definition, figuring out whether the machine will halt for a given input is impossible.

Since we're talking about input formats, another important piece of formality is formal languages and grammars. Specifically, a thing call the Chomsky hierarchy.

the Chomsky hierarchy defines 4 base classes of languages:

Recursively Enumerable
Context Sensitive
Context Free
Regular

each contains all the classes below it.
Why do we care about this for input validation?

Well, recognizing Recursively Enumerable languages is an undecidable problem. What do I mean? Well it's equivalent to trying to read and interpret a description of a turing machine--ie an interpreter.

All the other language classes can be reliably parsed. Parsing them is decidable. That means you can know that for any finite input, the machine reading it will eventually terminate.

Termination is a really handy property for a parser to have. Parsers that don't always terminate are balky finicky things and you can't trust them. Once you start parsing Recursively Enumerable things, you are in a world of pain because parsing is equivalent to running a turing machine!

Don't do that. When recognizing the input language is undecidable, you run the risk of having a formally proven unsecure system. Like perma-unsecure. Like there is no higher powered machine that you can use to make sure there are no holes. Your goose is cooked